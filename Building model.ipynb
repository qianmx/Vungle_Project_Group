{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%pylab inline\n",
    "\n",
    "from datetime import datetime,timedelta\n",
    "import json\n",
    "import re\n",
    "\n",
    "from collections import OrderedDict\n",
    "from math import pi\n",
    "import pytz\n",
    "import time\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale, normalize\n",
    "import seaborn.apionly as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import mmh3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linda/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('balanced_data.csv')\n",
    "data_im = pd.read_csv('imbalanced_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_install = data[data['is_install'] == 1]\n",
    "data_install_im = data_im[data_im['is_install'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def important_labels(colname,df,df_install):\n",
    "    ins = pd.DataFrame(df_install.groupby(colname)['is_install'].count().rename('install_counts')).reset_index()\n",
    "    total = pd.DataFrame(df.groupby(colname)['is_install'].count().rename('total_counts')).reset_index()\n",
    "    counts = total.merge(ins, how = 'left', on = colname).fillna(0.0)\n",
    "    counts['conversion'] = counts['install_counts']/counts['total_counts']\n",
    "    #ins_im = pd.DataFrame(df_install_im.groupby(colname)['is_install'].count().rename('install_counts')).reset_index()\n",
    "    #total_im = pd.DataFrame(df_im.groupby(colname)['is_install'].count().rename('total_counts')).reset_index()\n",
    "    #counts_im = total_im.merge(ins_im, how = 'left', on = colname).fillna(0.0)\n",
    "    #counts_im['conversion'] = counts_im['install_counts']/counts_im['total_counts']\n",
    "    #sub_counts_im = counts_im[((counts_im.install_counts>1)&(counts_im.conversion>0.2))|((counts_im.install_counts>5)&(counts_im.conversion<0.05)) ]\n",
    "    sub_counts = counts[((counts.install_counts>1)&(counts.conversion>0.5))|((counts.install_counts>5)&(counts.conversion<0.4))]\n",
    "        \n",
    "    return set(sub_counts[colname].values) #&set(sub_counts_im[colname].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_continent(x):\n",
    "    if len(str(x).split('/')) > 1:\n",
    "        return str(x).split('/')[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_city(x):\n",
    "    if len(str(x).split('/')) > 1:\n",
    "        return str(x).split('/')[1]\n",
    "    else:\n",
    "        return str(x).split('/')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    use crossvalidation (CV) to report the best parameter 'C'\n",
    "    parameter C: Inverse of regularization strength; must be a positive float. \n",
    "    Check LogisticRegression() in sklearn for more information\n",
    "    \"\"\"\n",
    "    print('Train Regression Model')\n",
    "    model = GridSearchCV(\n",
    "            estimator=LogisticRegression(),\n",
    "            param_grid={'C': [0.01, 0.02, 0.05, 0.1, 0.2, 0.5]},\n",
    "            scoring='log_loss',\n",
    "            cv=5\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_unknown(df, columns):\n",
    "    \"\"\"\n",
    "    convert NA to 'UNK'\n",
    "    \"\"\"\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        for col in columns:\n",
    "            df[col].fillna(\"UNK\", inplace=True)\n",
    "\n",
    "    if isinstance(df, dict):\n",
    "        for col in columns:\n",
    "            df[col][pd.isnull(df[col])] = \"UNK\"\n",
    "    return df\n",
    "          \n",
    "    \n",
    "def fillna0(df, columns):\n",
    "    \"\"\"\n",
    "    fill NA with 0\n",
    "    \"\"\"\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        for col in columns:\n",
    "            df[col].fillna(0, inplace=True)\n",
    "\n",
    "    if isinstance(df, dict):\n",
    "        for col in columns:\n",
    "            df[col][pd.isnull(df[col])] = 0    \n",
    "    return df\n",
    "\n",
    "\n",
    "def set_column_types(df, column_types_dict):\n",
    "    if isinstance(column_types_dict, dict):\n",
    "        for c, t in column_types_dict.items():\n",
    "            df[c] = df[c].astype(t)\n",
    "        return df \n",
    "    else:\n",
    "        raise TypeError()\n",
    "\n",
    "def preprocessing_data(df):\n",
    "    \"\"\"\n",
    "    clean data\n",
    "    \"\"\"\n",
    "    columns = {'is_install':int}\n",
    "    df = set_column_types(df, columns)\n",
    "    df = convert_to_unknown(df, ['advertiser_app_store_id',\n",
    "                                 'country_code',\n",
    "                                 'device_language',\n",
    "                                 'device_platform',\n",
    "                                 'time_zone'\n",
    "                            ])\n",
    "    df = fillna0(df, columns.keys())\n",
    "    \n",
    "    return df\n",
    "  \n",
    "class FeatureCreator():\n",
    "    \"\"\"Augment DataFrame-like input with new features.\"\"\"\n",
    "\n",
    "    def transform(self, X, inplace=False):\n",
    "        # TODO probably it's a good idea to restrict what fields from the\n",
    "        #      DataFrame are used to avoid copying the whole thing\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = {k: v.values for k, v in X.iteritems()}\n",
    "        if not inplace:\n",
    "            X = {k: np.copy(v) for k, v in X.iteritems()}\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hashing function\n",
    "def _murmur_32s(key, seed):\n",
    "\n",
    "    if isinstance(key, unicode):\n",
    "        bkey = key.encode('utf-8')\n",
    "    elif isinstance(key, bytes):\n",
    "        bkey = key\n",
    "    else:\n",
    "        print key\n",
    "        print type(key)\n",
    "        raise ValueError(\"the key must be either unicode or str\")\n",
    "    return mmh3.hash(bkey, seed)\n",
    "\n",
    "  \n",
    "# Hash features of DataFrame X using the hashing function\n",
    "def _transform(X, n_bits, categorical_features,\n",
    "              continuous_features, interaction_features,\n",
    "              store_fmap=False):\n",
    "    n_samples = X.shape[0] \\\n",
    "        if isinstance(X, pd.DataFrame) \\\n",
    "        else len(X.values()[0])\n",
    "    hash_mask = 2 ** n_bits - 1\n",
    "    n_features = \\\n",
    "        len(categorical_features) + \\\n",
    "        len(continuous_features) + \\\n",
    "        len(interaction_features)\n",
    "    n_hashed_features = n_samples * n_features\n",
    "    # assert n_hashed_features > 0\n",
    "    rows = np.empty(n_hashed_features, dtype=np.int32)\n",
    "    cols = np.empty(n_hashed_features, dtype=np.int32)\n",
    "    vals = np.zeros(n_hashed_features)\n",
    "    hashed_feature_idx = 0\n",
    "    f_map = {}\n",
    "\n",
    "    for f in categorical_features:\n",
    "        Xf = X[f]\n",
    "        hash_seed = _murmur_32s(f, 0)\n",
    "        for sample_idx in range(n_samples):\n",
    "            hash_value = _murmur_32s(Xf[sample_idx], hash_seed)\n",
    "            hash_sign = (hash_value >= 0) * 2 - 1\n",
    "\n",
    "            if store_fmap:\n",
    "                f_combined = ((f,), Xf[sample_idx])\n",
    "                if f_combined not in f_map:\n",
    "                    f_map[f_combined] = hash_value & hash_mask\n",
    "\n",
    "            rows[hashed_feature_idx] = sample_idx\n",
    "            cols[hashed_feature_idx] = hash_value & hash_mask\n",
    "            vals[hashed_feature_idx] += hash_sign\n",
    "            hashed_feature_idx += 1\n",
    "\n",
    "    for f in continuous_features:\n",
    "        Xf = X[f]\n",
    "        hash_value = _murmur_32s(f, 0)\n",
    "        hash_sign = (hash_value >= 0) * 2 - 1\n",
    "        if store_fmap:\n",
    "            f_combined = ((f,),)\n",
    "            f_map[f_combined] = hash_value & hash_mask\n",
    "        for sample_idx in range(n_samples):\n",
    "            rows[hashed_feature_idx] = sample_idx\n",
    "            cols[hashed_feature_idx] = hash_value & hash_mask\n",
    "            vals[hashed_feature_idx] += hash_sign * Xf[sample_idx]\n",
    "            hashed_feature_idx += 1\n",
    "\n",
    "    for feature_names in interaction_features:\n",
    "        hash_seed = 0\n",
    "        for f in feature_names:\n",
    "            hash_seed = _murmur_32s(f, hash_seed)\n",
    "\n",
    "        for sample_idx in range(n_samples):\n",
    "            hash_value = hash_seed\n",
    "            interaction_value = 1\n",
    "\n",
    "            value_cache = ()\n",
    "            for f in feature_names:\n",
    "                if f in continuous_features:\n",
    "                    interaction_value *= X[f][sample_idx]\n",
    "                    value_cache += (f,)\n",
    "                else:\n",
    "                    value_cache += (X[f][sample_idx],)\n",
    "                    hash_value = _murmur_32s(\n",
    "                        X[f][sample_idx], hash_value\n",
    "                    )\n",
    "\n",
    "            if store_fmap:\n",
    "                f_combined = (feature_names, value_cache)\n",
    "                if f_combined not in f_map:\n",
    "                    f_map[f_combined] = hash_value & hash_mask\n",
    "\n",
    "            hash_sign = (hash_value >= 0) * 2 - 1\n",
    "            rows[hashed_feature_idx] = sample_idx\n",
    "            cols[hashed_feature_idx] = hash_value & hash_mask\n",
    "            vals[hashed_feature_idx] += hash_sign * interaction_value\n",
    "            hashed_feature_idx += 1\n",
    "\n",
    "    n_dim_hashed_features = hash_mask + 1\n",
    "\n",
    "    # reverse k and v, if v is duplicated, append k to v\n",
    "    f_map_rev = {}\n",
    "    for k, v in f_map.items():\n",
    "        if v not in f_map_rev:\n",
    "            f_map_rev[v] = [k]\n",
    "        else:\n",
    "            f_map_rev[v] = f_map_rev[v] + [k]\n",
    "\n",
    "    return sparse.coo_matrix(\n",
    "        (vals, (rows, cols)),\n",
    "        (n_samples, n_dim_hashed_features)\n",
    "    ).tocsr(), f_map_rev\n",
    "\n",
    "# Wrapper class for hashing function\n",
    "class FeatureHasher(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,\n",
    "                 n_bits=22,\n",
    "                 categorical_features=None,\n",
    "                 continuous_features=None,\n",
    "                 interaction_features=None,\n",
    "                 store_fmap=False):\n",
    "        if n_bits < 1 or n_bits > 31:\n",
    "            raise ValueError(\"number of bits must be in interval [1, 31]\")\n",
    "\n",
    "        self.n_bits_ = n_bits\n",
    "        self.categorical_features_ = set(categorical_features or [])\n",
    "        self.continuous_features_ = set(continuous_features or [])\n",
    "        self.interaction_features_ = set(interaction_features or [])\n",
    "        self.store_fmap = store_fmap\n",
    "\n",
    "        n_features = len(self.categorical_features_) + \\\n",
    "                     len(self.continuous_features_) + \\\n",
    "                     len(self.interaction_features_)\n",
    "        if n_features == 0:\n",
    "            raise ValueError(\"at least one features needs to be specified\")\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return _transform(\n",
    "            X, self.n_bits_, self.categorical_features_,\n",
    "            self.continuous_features_, self.interaction_features_,\n",
    "            self.store_fmap\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['time_of_last_delivery_this_campaign', 'time_of_last_delivery_this_creative', 'time_of_last_delivery_any_installed_app',\n",
    "       'time_of_last_delivery_any_installed_app','time_of_last_vungle_delivery', 'time_of_this_impression','time_of_this_request']\n",
    "for col in cols:\n",
    "#     print col\n",
    "    data[col] =  pd.to_datetime(data[col]).dt.hour\n",
    "    data_im[col] =  pd.to_datetime(data_im[col]).dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linda/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "data['device_language'] = data['device_language'].apply(lambda x: str(x).lower().split('-')[0])\n",
    "data_install['device_language'] = data_install['device_language'].apply(lambda x: str(x).lower().split('-')[0])\n",
    "data_im['device_language'] = data_im['device_language'].apply(lambda x: str(x).lower().split('-')[0])\n",
    "data_install_im['device_language'] = data_install_im['device_language'].apply(lambda x: str(x).lower().split('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linda/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "data['time_zone_continent'] = data['time_zone'].apply(lambda x: get_continent(x))\n",
    "data_install['time_zone_continent'] = data_install['time_zone'].apply(lambda x: get_continent(x))\n",
    "data_im['time_zone_continent'] = data_im['time_zone'].apply(lambda x: get_continent(x))\n",
    "data_install_im['time_zone_continent'] = data_install_im['time_zone'].apply(lambda x: get_continent(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#might have device_language/country_code multicolinearity \n",
    "X_col = ['advertiser_app_store_id','country_code','n_campaign_views','device_language','device_platform','time_zone']\n",
    "y = ['is_install']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>advertiser_app_store_id</th>\n",
       "      <th>country_code</th>\n",
       "      <th>n_campaign_views</th>\n",
       "      <th>device_language</th>\n",
       "      <th>device_platform</th>\n",
       "      <th>time_zone</th>\n",
       "      <th>is_install</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1009442510</td>\n",
       "      <td>CN</td>\n",
       "      <td>4</td>\n",
       "      <td>zh</td>\n",
       "      <td>iOS</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5743f032a5a36ff4300000a5</td>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>id</td>\n",
       "      <td>android</td>\n",
       "      <td>Asia/Makassar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>727296976</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>iOS</td>\n",
       "      <td>America/Toronto</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57a28ffbb019f8257c00021d</td>\n",
       "      <td>LA</td>\n",
       "      <td>1</td>\n",
       "      <td>th</td>\n",
       "      <td>iOS</td>\n",
       "      <td>Asia/Bangkok</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>com.plarium.vikings</td>\n",
       "      <td>CZ</td>\n",
       "      <td>0</td>\n",
       "      <td>cs</td>\n",
       "      <td>android</td>\n",
       "      <td>Europe/Prague</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    advertiser_app_store_id country_code  n_campaign_views device_language  \\\n",
       "0                1009442510           CN                 4              zh   \n",
       "1  5743f032a5a36ff4300000a5           ID                 0              id   \n",
       "2                 727296976           CA                 0              en   \n",
       "3  57a28ffbb019f8257c00021d           LA                 1              th   \n",
       "4       com.plarium.vikings           CZ                 0              cs   \n",
       "\n",
       "  device_platform        time_zone  is_install  \n",
       "0             iOS    Asia/Shanghai           0  \n",
       "1         android    Asia/Makassar           0  \n",
       "2             iOS  America/Toronto           0  \n",
       "3             iOS     Asia/Bangkok           0  \n",
       "4         android    Europe/Prague           0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[X_col+y].copy().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_clf = preprocessing_data(data[X_col+y].copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Model Features - specify categorical, continuous, and interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##you can't put integer column into this\n",
    "## if you add something, please change the preprocessing function as well.\n",
    "cat_features_pc = [\n",
    "    'advertiser_app_store_id',\n",
    "    'country_code',\n",
    "    'device_language',\n",
    "    'device_platform',\n",
    "    'time_zone'\n",
    "    ]\n",
    "\n",
    "cont_features_pc = []\n",
    "\n",
    "cat_interactions_pc = [\n",
    "     ('advertiser_app_store_id',  'country_code'),\n",
    "     ('country_code', 'device_language')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Creating/Hashing Train\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(X_clf, test_size=0.2, random_state = 27)  # splitting Train into Train/Test sets\n",
    "X_train, y_train, X_test, y_test = train, train.pop('is_install'), test, test.pop('is_install')\n",
    "\n",
    "# Feature Hashing\n",
    "print('Feature Creating/Hashing Train')\n",
    "feature_creator = FeatureCreator()\n",
    "design_matrix_transformer = FeatureHasher(\n",
    "    18, cat_features_pc, None, cat_interactions_pc, store_fmap=True) # You can experiment with hasher bits (we used 18 here)\n",
    "\n",
    "X_test = feature_creator.transform(X_test, inplace=True)\n",
    "X_test, f_map = design_matrix_transformer.fit_transform(X_test)\n",
    "\n",
    "X_train = feature_creator.transform(X_train, inplace=True)\n",
    "X_train, f_map = design_matrix_transformer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560000, 262144)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Regression Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter:  {'C': 0.2}\n",
      "Log Loss (Validation): 0.596766\n",
      "Log Loss (Train): 0.590061\n",
      "AUC (Train): 0.751594\n",
      "Log Loss (Test): 0.594483\n",
      "AUC (Test): 0.746766\n"
     ]
    }
   ],
   "source": [
    "logistic_baseline = logistic_model(X_train, y_train)\n",
    "\n",
    "# Calculate prediction/probability of train and test\n",
    "X_train_predictions = logistic_baseline.predict(X_train)\n",
    "X_train_predprob = logistic_baseline.predict_proba(X_train)[:, 1]\n",
    "\n",
    "X_test_predictions = logistic_baseline.predict(X_test)\n",
    "X_test_predprob = logistic_baseline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics of train, validation and test set.\n",
    "lr_ll_val = -logistic_baseline.best_score_\n",
    "\n",
    "lr_ll_train = log_loss(y_train, X_train_predprob)\n",
    "lr_auc_train = roc_auc_score(y_train, X_train_predprob)\n",
    "\n",
    "lr_ll_test = log_loss(y_test, X_test_predprob)    \n",
    "lr_auc_test = roc_auc_score(y_test, X_test_predprob)\n",
    "\n",
    "# Print out the results\n",
    "print \"Best parameter: \", logistic_baseline.best_params_\n",
    "\n",
    "print \"Log Loss (Validation): %f\" % lr_ll_val\n",
    "\n",
    "print \"Log Loss (Train): %f\" % lr_ll_train\n",
    "print \"AUC (Train): %f\" % lr_auc_train\n",
    "\n",
    "print 'Log Loss (Test): %f' % lr_ll_test\n",
    "print 'AUC (Test): %f' % lr_auc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Only create labels for one that is either over performed/ under performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#might have device_language/country_code multicolinearity \n",
    "X_col = ['advertiser_app_store_id','country_code','device_language','device_platform','time_zone']\n",
    "\n",
    "labels=[]\n",
    "for i in X_col:\n",
    "    labels.append(important_labels(i,data,data_install))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_clf = preprocessing_data(data[X_col+y].copy())\n",
    "train, test = train_test_split(X_clf, test_size=0.2, random_state = 27)  # splitting Train into Train/Test sets\n",
    "X_train, y_train, X_test, y_test = train, train.pop('is_install'), test, test.pop('is_install')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linda/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(labels)):\n",
    "    pattern = '|'.join(list(labels[0]))\n",
    "    X_train.loc[~X_train[X_col[i]].str.contains(pattern),X_col[i]]='Other'+str(i)\n",
    "    X_test.loc[~X_test[X_col[i]].str.contains(pattern),X_col[i]]='Other'+str(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Creating/Hashing Train\n"
     ]
    }
   ],
   "source": [
    "# Feature Hashing\n",
    "print('Feature Creating/Hashing Train')\n",
    "feature_creator = FeatureCreator()\n",
    "design_matrix_transformer = FeatureHasher(\n",
    "    18, cat_features_pc, None, cat_interactions_pc, store_fmap=True) # You can experiment with hasher bits (we used 18 here)\n",
    "\n",
    "X_test = feature_creator.transform(X_test, inplace=True)\n",
    "X_test, f_map = design_matrix_transformer.fit_transform(X_test)\n",
    "\n",
    "X_train = feature_creator.transform(X_train, inplace=True)\n",
    "X_train, f_map = design_matrix_transformer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560000, 262144)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Regression Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/linda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter:  {'C': 0.5}\n",
      "Log Loss (Validation): 0.609129\n",
      "Log Loss (Train): 0.608264\n",
      "AUC (Train): 0.728830\n",
      "Log Loss (Test): 0.607242\n",
      "AUC (Test): 0.730329\n"
     ]
    }
   ],
   "source": [
    "logistic_baseline = logistic_model(X_train, y_train)\n",
    "\n",
    "# Calculate prediction/probability of train and test\n",
    "X_train_predictions = logistic_baseline.predict(X_train)\n",
    "X_train_predprob = logistic_baseline.predict_proba(X_train)[:, 1]\n",
    "\n",
    "X_test_predictions = logistic_baseline.predict(X_test)\n",
    "X_test_predprob = logistic_baseline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics of train, validation and test set.\n",
    "lr_ll_val = -logistic_baseline.best_score_\n",
    "\n",
    "lr_ll_train = log_loss(y_train, X_train_predprob)\n",
    "lr_auc_train = roc_auc_score(y_train, X_train_predprob)\n",
    "\n",
    "lr_ll_test = log_loss(y_test, X_test_predprob)    \n",
    "lr_auc_test = roc_auc_score(y_test, X_test_predprob)\n",
    "\n",
    "# Print out the results\n",
    "print \"Best parameter: \", logistic_baseline.best_params_\n",
    "\n",
    "print \"Log Loss (Validation): %f\" % lr_ll_val\n",
    "\n",
    "print \"Log Loss (Train): %f\" % lr_ll_train\n",
    "print \"AUC (Train): %f\" % lr_auc_train\n",
    "\n",
    "print 'Log Loss (Test): %f' % lr_ll_test\n",
    "print 'AUC (Test): %f' % lr_auc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### compare to when we have all the features without feature reduction\n",
    "\n",
    "Best parameter:  {'C': 0.2}\n",
    "Log Loss (Validation): 0.596766\n",
    "Log Loss (Train): 0.590061\n",
    "AUC (Train): 0.751594\n",
    "Log Loss (Test): 0.594483\n",
    "AUC (Test): 0.746766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
